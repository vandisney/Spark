<img src="https://github.com/vandisney/Spark/blob/main/imagens/spark_logo.jpg" width="200"/>

Exercícios – Testar o Jupyter Notebook

1. Criar o arquivo do notebook com o nome teste_spark.ipynb

new, clicar em pyspark, já vem com a sessão(explicar) e o contexto de spark(explicar) criado.
<img src="https://github.com/vandisney/Spark/blob/main/imagens/sessao.png"/>
<img src="https://github.com/vandisney/Spark/blob/main/imagens/sessao2.png"/>

2. Obter as informações da sessão de spark (spark)

precionando spark + (chift+enter)do teclado, ele executa a celula e cria uma nova célula em baixo.
nessa sessão do spark tem um contexto, tem a interface grafica, qual a versão e modo que está rodando.
<img src="https://github.com/vandisney/Spark/blob/main/imagens/sessao3.png"/>

3. Obter as informações do contexto do spark (sc)
Digita sc + (ctrl+enter), executa porém não é criado nova célula.


4. Setar o log como INFO.
<img src="https://github.com/vandisney/Spark/blob/main/imagens/sessao4.png"/>
faz parte da sessão do spark, para isso digita spark. (+ tab)
 <img src="https://github.com/vandisney/Spark/blob/main/imagens/sessao5.png"/>

5. Visualizar todos os banco de dados com o catalog

6. Ler os dados "hdfs://namenode:8020/user/rodrigo/data/juros_selic/juros_selic.json“ com uso de Dataframe

7. Salvar o Dataframe como juros no formato de tabela Hive

8. Visualizar todas as tabelas com o catalog

9. Visualizar no hdfs o formato e compressão que está a tabela juros do Hive

10. Ler e visualizar os dados da tabela juros, com uso de Dataframe no formato de Tabela Hive

11. Ler e visualizar os dados da tabela juros , com uso de Dataframe no formato Parquet

12. Clicar no botão de Enviar Tarefa, e enviar o texto: ok
